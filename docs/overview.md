# NovaDev â€” Program Ã–zeti (0â†’Prod, 8 Hafta)

**"Ã–ÄŸrenirken Gemi Yapan" Ãœretim ProgramÄ±**

> Bu bir "AI kursu" deÄŸil; teori + pratik + Ã¼rÃ¼n birlikte ilerleyen bir **yaparak Ã¶ÄŸrenme protokolÃ¼**.

---

## ğŸ¯ AmaÃ§ (North Star)

### Temel Hedef
**"ML zihni" kur + uÃ§tan uca bir AI servisini Ã§alÄ±ÅŸÄ±r halde yayÄ±na al.**

### Ã‡Ä±ktÄ± Seti
1. âœ… **Ã–lÃ§Ã¼lebilir mini-modeller**
   - Linear regression (MSE < 0.5)
   - MLP + MNIST (accuracy â‰¥ 0.97)
   - BERT fine-tune (F1 â‰¥ 0.85)

2. âœ… **RAG + Tool-Agent prototipi**
   - Retrieval-augmented generation
   - AraÃ§ kullanan ajan (tool calling)

3. âœ… **FastAPI servis**
   - `/healthz`, `/chat`, `/rag` endpoints
   - Rate limiting + basic metrics
   - Docker Compose deployment

4. âœ… **Capstone demo**
   - 5 dakikalÄ±k video
   - Kurulum adÄ±mlarÄ± (â‰¤ 10 dk)
   - README + Ã§alÄ±ÅŸan kod

### BaÅŸarÄ± Kriteri
> **"AynÄ±sÄ±nÄ± yarÄ±n tek baÅŸÄ±na kurabilir misin?" â†’ EVET**

---

## ğŸ‘¥ Kime GÃ¶re?

### Hedef Kitle
- âœ… Python bilen
- âœ… ML/AI'ye **sistemli** girmek isteyen geliÅŸtirici
- âœ… Kod ezberi deÄŸil, **neden Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±** anlamak isteyen

### DonanÄ±m
- **Apple Silicon (M1/M2/M3)**
- MPS (Metal Performance Shaders) ile rahat ilerliyoruz
- CPU fallback mevcut

### Zaman TaahhÃ¼dÃ¼
```
GÃ¼nlÃ¼k:  2-3 saat
HaftalÄ±k: 5 gÃ¼n
Toplam: ~80-100 saat (8 hafta)
```

---

## ğŸ§± Program Mimarisi (3 Hat Birlikte)

### 1ï¸âƒ£ Temel (T) â€” Kavram + Sezgi
```
SÃ¼re: HaftalÄ±k 45-60 dk
Format: Teori notlarÄ± (theory_*.md)
AmaÃ§: "Neden?" sorularÄ±na cevap
```

**Neler Ã–ÄŸreniliyor:**
- Loss fonksiyonlarÄ±nÄ±n probabilistik kÃ¶kenleri
- Optimizasyon matematiÄŸi
- Overfit/underfit dinamikleri
- Regularization teorisi

### 2ï¸âƒ£ Pratik (P) â€” Kod & Deney
```
SÃ¼re: GÃ¼nlÃ¼k 60-90 dk
Format: Python scripts + Jupyter notebooks
AmaÃ§: KÃ¼Ã§Ã¼k ama Ã¶lÃ§Ã¼lebilir koÅŸular
```

**Neler YapÄ±lÄ±yor:**
- Manuel gradient descent
- Ablation studies
- Hyperparameter sweeps
- Loss curve analysis

### 3ï¸âƒ£ ÃœrÃ¼n (X) â€” Servis & Ä°zleme
```
SÃ¼re: HaftalÄ±k 60-90 dk
Format: API endpoints + Docker
AmaÃ§: Ã‡Ä±ktÄ±yÄ± kullanÄ±cÄ±ya ulaÅŸtÄ±r
```

**Neler Kurulyor:**
- REST API endpoints
- Health checks
- Basic monitoring
- Deployment pipeline

### T â†’ P â†’ X DÃ¶ngÃ¼sÃ¼
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TEMEL (T)                           â”‚
â”‚ "Neden MSE?"                        â”‚
â”‚ â†’ Gaussian MLE baÄŸlantÄ±sÄ±           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PRATÄ°K (P)                          â”‚
â”‚ MSE kodla, L2 ekle                  â”‚
â”‚ â†’ Val MSE < 0.5 yap                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ÃœRÃœN (X)                            â”‚
â”‚ /predict endpoint kur               â”‚
â”‚ â†’ Docker'da Ã§alÄ±ÅŸtÄ±r                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â± AkÄ±ÅŸ (GÃ¼n / Hafta Ritmi)

### GÃ¼nlÃ¼k Ritim (2-3 saat)

#### Sabah (30 dk)
```
1. Hedef belirle (1 cÃ¼mle)
   "Val MSE < 0.4 yapmak"

2. Plan yap (3 madde)
   - LR sweep (1e-3, 5e-3, 1e-2)
   - Early stopping on
   - L2=1e-3 sabit

3. Teori notunu oku (15-30 dk)
   Ä°lgili theory bÃ¶lÃ¼mÃ¼nÃ¼ hÄ±zlÄ± tara
```

#### Ã–ÄŸlen (90 dk)
```
4. Kod/Deney yap (60-90 dk)
   - Script'leri koÅŸ
   - Metrikleri kaydet
   - Grafikleri oluÅŸtur

5. GÃ¶zlem yap
   - Ne iÅŸe yaradÄ±?
   - Neden?
```

#### AkÅŸam (15 dk)
```
6. Log + Ã–zet (10-15 dk)
   - exp_log.csv'ye yaz
   - daily_log.md'ye not dÃ¼ÅŸ
   - Git commit

7. YarÄ±n iÃ§in hazÄ±rlÄ±k (5 dk)
   - Sonraki hedefi belirle
```

### HaftalÄ±k Ritim

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PAZARTESÄ°: Hedef & Plan               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - HaftalÄ±k metrik eÅŸiÄŸini belirle     â”‚
â”‚ - 5 gÃ¼nlÃ¼k plan yap                    â”‚
â”‚ - Teori notlarÄ±nÄ± tara                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SALI-Ã‡ARÅAMBA-PERÅEMBE: Deneyler      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Baseline kur                         â”‚
â”‚ - Ablation studies yap                 â”‚
â”‚ - Hyperparameter sweep                 â”‚
â”‚ - Her gÃ¼n: commit + log                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CUMA: Rapor & Demo                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - HaftalÄ±k rapor yaz (1 sayfa)        â”‚
â”‚ - Kod temizliÄŸi (lint, test)          â”‚
â”‚ - KÃ¼Ã§Ã¼k demo (CLI/HTTP)                â”‚
â”‚ - Git tag (week-X-complete)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—º Syllabus & Kilometre TaÅŸlarÄ±

### Week 0 â€” Temel Zihin âœ… TAMAMLANDI

**Konular:**
- Veri ayrÄ±mÄ± (train/val/test)
- Loss fonksiyonlarÄ± (MSE, CE)
- Learning rate davranÄ±ÅŸÄ±
- Overfit/underfit teÅŸhisi
- Tensor & autograd

**Ã‡Ä±ktÄ±lar:**
- âœ… 7061 satÄ±r teori notlarÄ± (7 dÃ¶kÃ¼man)
- âœ… Week 0 kapanÄ±ÅŸ dÃ¶kÃ¼manÄ± (self-assessment)
- âœ… MPS test geÃ§ti
- âœ… pytest/ruff yeÅŸil

**Definition of Done:**
```
â–¡ theory_closure.md tamamlandÄ±
â–¡ Self-check listesi âœ“
â–¡ MPS functional test geÃ§ti
â–¡ Setup verified
```

---

### Week 1 â€” Linear Regression (Konveks KampÄ±)

**Konular:**
- Neden MSE? (Gaussian MLE)
- Ã–lÃ§ekleme etkisi (condition number)
- Early stopping vs L2
- LR davranÄ±ÅŸÄ± (semptomlar)

**Pratik:**
- Sentetik veri oluÅŸturma
- Manuel gradient descent
- nn.Module ile training
- Train/val split + early stopping

**Metrik EÅŸiÄŸi:** ğŸ¯ **Val MSE < 0.5**

**Ã‡Ä±ktÄ±lar:**
- Loss curve grafiÄŸi (train + val)
- exp_log.csv (5+ deney)
- week1_report.md (teori baÄŸlantÄ±lÄ±)
- Overfit Ã¶rneÄŸi (L2=0 koÅŸusu)

**Definition of Done:**
```
â–¡ Val MSE < 0.5 âœ“
â–¡ Loss curves (normal + overfit)
â–¡ Ablation: scaling var/yok
â–¡ Week 0 teori baÄŸlantÄ±sÄ± aÃ§Ä±klandÄ±
â–¡ pytest yeÅŸil
```

---

### Week 2 â€” MLP + MNIST

**Konular:**
- Non-linearity neden gerekli?
- Multi-layer backpropagation
- DataLoader & batching
- Classification metrics (accuracy, precision, recall)

**Pratik:**
- MNIST dataset
- 2-layer MLP
- ReLU/GELU activation
- Cross-entropy loss
- Confusion matrix

**Metrik EÅŸiÄŸi:** ğŸ¯ **Test Accuracy â‰¥ 0.97**

**Ã‡Ä±ktÄ±lar:**
- Accuracy curve
- Confusion matrix
- Error analysis (yanlÄ±ÅŸ sÄ±nÄ±flanan Ã¶rnekler)
- week2_report.md

**Definition of Done:**
```
â–¡ Test acc â‰¥ 0.97 âœ“
â–¡ Confusion matrix gÃ¶rselleÅŸtirildi
â–¡ 10+ yanlÄ±ÅŸ Ã¶rnek analizi
â–¡ Overfit kontrolÃ¼ (early stopping loglarÄ±)
```

---

### Week 3 â€” NLP Temeli (TÃ¼rkÃ§e BERT)

**Konular:**
- Tokenization (BPE/WordPiece)
- Pre-trained models (DistilBERT)
- Fine-tuning kÃ¼Ã§Ã¼k veri ile
- F1 score & error analysis

**Pratik:**
- Sentiment analysis (TÃ¼rkÃ§e)
- dbmdz/bert-base-turkish-cased
- Train/val split (kÃ¼Ã§Ã¼k dataset)
- Error categorization

**Metrik EÅŸiÄŸi:** ğŸ¯ **F1 â‰¥ 0.85**

**Ã‡Ä±ktÄ±lar:**
- F1, precision, recall scores
- Confusion matrix
- Error analysis table (false positives/negatives)
- week3_report.md

**Definition of Done:**
```
â–¡ F1 â‰¥ 0.85 âœ“
â–¡ Confusion matrix + analiz
â–¡ Error categorization (3+ kategori)
â–¡ Tokenization pipeline dokÃ¼mente edildi
```

---

### Week 4 â€” RAG (Retrieval-Augmented Generation)

**Konular:**
- Chunking strategies (500-800 token)
- Sentence embeddings (bge-small)
- Vector databases (FAISS/Chroma)
- Prompt composition

**Pratik:**
- Kendi notlarÄ±nÄ± indexle
- FAISS index oluÅŸtur
- Top-k retrieval
- LLM ile yanÄ±t oluÅŸtur (Ollama)

**Metrik EÅŸiÄŸi:** ğŸ¯ **Top-k Recall â‰¥ %60**

**Ã‡Ä±ktÄ±lar:**
- `cli.py "soru"` â†’ kaynaklÄ± yanÄ±t
- Recall@k metrics
- Chunking ablation
- week4_report.md

**Definition of Done:**
```
â–¡ Top-k recall â‰¥ %60 âœ“
â–¡ CLI interface Ã§alÄ±ÅŸÄ±yor
â–¡ Kaynak atÄ±flarÄ± doÄŸru
â–¡ Chunking stratejisi dokÃ¼mente edildi
```

---

### Week 5 â€” Tool-Agent (AraÃ§ Kullanan Ajan)

**Konular:**
- Function calling
- Tool schema definition
- Agent loop (plan â†’ call â†’ observe â†’ respond)
- Error handling

**Pratik:**
- En az 2 tool: `search()`, `math()`
- Tool calling pipeline
- Agent dÃ¶ngÃ¼sÃ¼
- Logging (her adÄ±m)

**Metrik EÅŸiÄŸi:** ğŸ¯ **2-step tool chain baÅŸarÄ±lÄ±**

**Ã‡Ä±ktÄ±lar:**
- Tool definitions (JSON schema)
- Agent conversation logs
- Multi-step example (2+ tools)
- week5_report.md

**Definition of Done:**
```
â–¡ 2-step tool chain Ã§alÄ±ÅŸÄ±yor âœ“
â–¡ Tool calling loglarÄ± net
â–¡ Error handling test edildi
â–¡ Example dialog dokÃ¼mente edildi
```

---

### Week 6 â€” LoRA Fine-tune (7B Model)

**Konular:**
- PEFT (Parameter-Efficient Fine-Tuning)
- LoRA (Low-Rank Adaptation)
- Domain adaptation
- Evaluation (qualitative)

**Pratik:**
- 7B model (Llama/Qwen)
- LoRA configuration (r=8, alpha=16)
- Domain dataset (kendi notlarÄ±n)
- Before/after comparison

**Metrik EÅŸiÄŸi:** ğŸ¯ **Qualitative improvement (A/B blind test)**

**Ã‡Ä±ktÄ±lar:**
- LoRA checkpoint
- Before/after examples (5+ pairs)
- Blind evaluation results
- week6_report.md

**Definition of Done:**
```
â–¡ LoRA training tamamlandÄ± âœ“
â–¡ Before/after Ã¶rnekleri var (5+)
â–¡ Blind evaluation yapÄ±ldÄ±
â–¡ Improvement documented
```

---

### Week 7 â€” ServisleÅŸtir & Ä°zle

**Konular:**
- FastAPI structure
- Endpoint design
- Rate limiting
- Basic monitoring (metrics)
- Docker deployment

**Pratik:**
- `/healthz` endpoint
- `/chat` endpoint (LLM)
- `/rag` endpoint (retrieval)
- Prometheus-style `/metrics`
- Docker Compose

**Metrik EÅŸiÄŸi:** ğŸ¯ **p95 latency < 2.5s**

**Ã‡Ä±ktÄ±lar:**
- FastAPI service
- Docker Compose config
- Metrics dashboard (basic)
- week7_report.md

**Definition of Done:**
```
â–¡ Docker Compose up Ã§alÄ±ÅŸÄ±yor âœ“
â–¡ 3 endpoint (healthz, chat, rag) test edildi
â–¡ p95 latency < 2.5s
â–¡ Rate limiting aktif
â–¡ /metrics endpoint var
```

---

### Week 8 â€” Capstone

**Konular:**
- System integration
- Demo preparation
- Documentation
- Retrospective

**Pratik:**
- RAG + Agent + Service entegrasyonu
- End-to-end flow
- Video demo (5 dk)
- README kurulum (â‰¤ 10 dk)

**Metrik EÅŸiÄŸi:** ğŸ¯ **3 soru akÄ±ÅŸÄ± videosu**

**Ã‡Ä±ktÄ±lar:**
- 5 dakikalÄ±k demo video
- README.md (kurulum adÄ±mlarÄ±)
- REPORT.md (retrospektif)
- "Ne Ã¶ÄŸrendim / Ne eksik" analizi
- v2 hedefleri

**Definition of Done:**
```
â–¡ 5 dk video demo âœ“
â–¡ 3 soru akÄ±ÅŸÄ± gÃ¶sterildi
â–¡ README kurulum < 10 dk test edildi
â–¡ Retrospektif rapor tamamlandÄ±
â–¡ v2 roadmap var
```

---

## ğŸ“ DeÄŸerlendirme & GeÃ§iÅŸ EÅŸiÄŸi (Gating)

### Her Hafta Gerekli (Gating Criteria)

#### 1. Metrik EÅŸiÄŸi
```
Week 1: Val MSE < 0.5
Week 2: Test acc â‰¥ 0.97
Week 3: F1 â‰¥ 0.85
Week 4: Recall@k â‰¥ 60%
Week 5: 2-step tool chain
Week 6: Qualitative improvement
Week 7: p95 < 2.5s
Week 8: 3 soru akÄ±ÅŸÄ±
```

**Kural:** EÅŸiÄŸi geÃ§meden sonraki haftaya geÃ§me!

#### 2. Artifact (KanÄ±t)
```
- Grafik (loss curve, confusion matrix)
- Log (exp_log.csv, metrics.json)
- Rapor (weekX_report.md)
```

#### 3. Ã–zet (3-5 Madde)
```
Ne Ã§alÄ±ÅŸtÄ±?
Ne Ã§alÄ±ÅŸmadÄ±?
Neden? (teori baÄŸlantÄ±sÄ±)
Bir dahaki sefere?
```

### GeÃ§iÅŸ KuralÄ±
```
âŒ EÅŸik geÃ§ilmedi â†’ AynÄ± haftayÄ± tekrar
   (BorÃ§ bÃ¼yÃ¼r, Week 8'e ulaÅŸamazsÄ±n)

âœ… EÅŸik geÃ§ildi â†’ Sonraki haftaya
   (Ã–zgÃ¼venle devam)
```

---

## ğŸ—ƒ Ã‡Ä±ktÄ±lar & Portfolio

### KlasÃ¶r YapÄ±sÄ±
```
novadev-protocol/
â”œâ”€â”€ outputs/               # Metrikler & grafikler
â”‚   â”œâ”€â”€ loss_curves/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â”œâ”€â”€ exp_log.csv
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ reports/               # HaftalÄ±k raporlar
â”‚   â”œâ”€â”€ week1_report.md
â”‚   â”œâ”€â”€ week2_report.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ demo/                  # Capstone
â”‚   â”œâ”€â”€ capstone_demo.mp4
â”‚   â”œâ”€â”€ demo.gif
â”‚   â””â”€â”€ screenshots/
â”‚
â””â”€â”€ docs/                  # DÃ¶kÃ¼mantasyon
    â”œâ”€â”€ overview.md (bu dosya)
    â”œâ”€â”€ week0_kapanis.md
    â””â”€â”€ architecture.md
```

### Portfolio Ä°Ã§eriÄŸi
```
1. GitHub Repo
   - README.md (kurulum < 10 dk)
   - Clean code (lint, test)
   - Commit history (her gÃ¼n)

2. Metrics & Graphs
   - Loss curves
   - Confusion matrices
   - Recall@k tables

3. Reports
   - 8 haftalÄ±k rapor
   - Teori baÄŸlantÄ±larÄ±
   - Ablation studies

4. Demo
   - 5 dk video
   - GIF preview
   - Live deployment (opsiyonel)
```

**Portfolyo > Sertifika**
> Bu repo = CV'de gÃ¶sterebileceÄŸin **KANIT**

---

## ğŸ”§ AraÃ§lar / Stack

### Kod & ML
```
Python 3.11+
PyTorch 2.x (MPS support)
scikit-learn
transformers (Hugging Face)
sentence-transformers
```

### Veri
```
torchvision/datasets (MNIST)
Hugging Face datasets
Kendi notlarÄ±n (RAG iÃ§in)
```

### Servis & Deployment
```
FastAPI
Uvicorn
Docker & Docker Compose
```

### Arama & Embedding
```
FAISS / Chroma
bge-small (sentence embeddings)
```

### LLM
```
Ollama (lokal 7B/8B)
API fallback (OpenAI/Anthropic)
```

### Ä°zleme (Basic)
```
/metrics endpoint (Prometheus-style)
JSONL logs
```

### GeliÅŸtirme
```
pytest (testing)
ruff (linting)
Git (version control)
```

---

## ğŸ§­ Pedagoji (Neden BÃ¶yle?)

### 1. Sarmal Ã–ÄŸrenme
```
Her hafta = Ã–nceki hafta + Yeni kavram

Week 1: Linear regression (MSE)
Week 2: MLP (MSE â†’ CE)
Week 3: BERT (CE â†’ F1)
Week 4: RAG (Embeddings)
...

Her adÄ±mda Ã¶nceki bilgi PEKÄ°ÅÄ°YOR
```

### 2. Minimum Teori, Ã–lÃ§Ã¼lebilir Pratik
```
Teori: Sadece "neden"ler (45-60 dk/hafta)
Pratik: Ã–lÃ§Ã¼lebilir metrik (her gÃ¼n)

âŒ "ÅÃ¶yle yapÄ±lÄ±r" (ezber)
âœ… "Neden bÃ¶yle yapÄ±yoruz?" (anlayÄ±ÅŸ)
```

### 3. Ablation Disiplini
```
Soru: "L2 gerÃ§ekten iÅŸe yarÄ±yor mu?"

Cevap: Tahmin deÄŸil, KANIT!
  - L2=0 koÅŸusu: Val MSE = 0.45
  - L2=1e-3 koÅŸusu: Val MSE = 0.18
  â†’ L2 iÅŸe yarÄ±yor âœ“

Her iddia = Deney ile doÄŸrulanmÄ±ÅŸ
```

### 4. Product-First
```
Klasik Kurs:
  Teori â†’ Pratik â†’ (Belki) Proje

NovaDev:
  Teori â†’ Pratik â†’ ÃœRÃœN (her hafta)
  
Week 1 sonu: Ã‡alÄ±ÅŸan regresyon scripti
Week 4 sonu: RAG CLI Ã§alÄ±ÅŸÄ±yor
Week 7 sonu: API deploy edildi

Ã‡alÄ±ÅŸan uÃ§ nokta â†’ Motivasyon â†‘
```

### 5. Hata OdaklÄ± Ã–ÄŸrenme
```
Sorun Ã§Ä±kmasÄ± = Ã–ÄŸrenme fÄ±rsatÄ±

NaN gÃ¶rdÃ¼n mÃ¼?
â†’ LR Ã§ok bÃ¼yÃ¼k (theory'de vardÄ±!)

Val loss yÃ¼kseliyor mu?
â†’ Overfit (theory_closure.md, BÃ¶lÃ¼m 4)

Hata â†’ Teori â†’ Ã‡Ã¶zÃ¼m â†’ Ã–ÄRENME
```

---

## ğŸ§¯ TÄ±kandÄ±ÄŸÄ±nda HÄ±zlÄ± TeÅŸhis

### 6 AdÄ±mlÄ±k Checklist

```
1. LR Ã§ok mu? (NaN/Inf/salÄ±nÄ±m)
   â†’ LR'Ä± yarÄ±ya indir

2. Ã–lÃ§ekleme var mÄ±? (StandardScaler)
   â†’ Feature standardization ekle

3. Grad sÄ±fÄ±rlama doÄŸru mu?
   â†’ optimizer.zero_grad() kontrol et

4. Loss/Metric uyumu doÄŸru mu?
   â†’ Regresyon: MSE, SÄ±nÄ±flama: CE

5. Shape/Dtype/Device tutarlÄ± mÄ±?
   â†’ print(x.shape, x.dtype, x.device)

6. Seed & Tekrar (sonuÃ§ niye zÄ±plÄ±yor?)
   â†’ torch.manual_seed(42) ekle
```

**Referans:** `week0_setup/theory_closure.md`

---

## ğŸ“ Beklentiler (GerÃ§ekÃ§i)

### Zaman
```
HaftalÄ±k 5-8 saat  â†’ Tamam âœ“
HaftalÄ±k 10+ saat  â†’ Åahane âœ“âœ“
HaftalÄ±k < 5 saat  â†’ EÅŸikleri geÃ§emezsin âœ—
```

### Kod Kalitesi
```
âŒ "MÃ¼kemmel" kod (gereksiz)
âœ… Ã–lÃ§Ã¼lebilir geliÅŸim (gerekli)
âœ… Test geÃ§en kod (ÅŸart)
âœ… Lint temiz kod (ÅŸart)
```

### Demo
```
Haftada en az 1 demo:
  - CLI tool
  - HTTP endpoint
  - Jupyter notebook
  - Grafik/visualizasyon
```

### Rapor
```
HaftalÄ±k 1 sayfa rapor (ÅART)

Format:
  - Hedef (1 cÃ¼mle)
  - SonuÃ§ (metrik)
  - GÃ¶zlem (3-5 madde)
  - Teori baÄŸlantÄ±sÄ±
  - SÄ±radaki adÄ±m
```

---

## âœ… BugÃ¼nÃ¼n Sonraki AdÄ±mÄ±

### Week 0 KapanÄ±ÅŸÄ± (BugÃ¼n)
```
1. docs/overview.md oluÅŸturuldu âœ“ (bu dosya)
2. week0_setup/theory_closure.md tamamlandÄ± âœ“
3. Self-check yapÄ±ldÄ± mÄ±?
   â–¡ Train/Val/Test farkÄ±nÄ± biliyorum
   â–¡ MSE/MAE/Huber ne zaman kullanÄ±lÄ±r biliyorum
   â–¡ LR semptomlarÄ±nÄ± tanÄ±yorum
   â–¡ Overfit/Underfit teÅŸhis edebiliyorum
   â–¡ Week 0'Ä± Ã–ZÃœMSEDIM âœ“
```

### Week 1 BaÅŸlangÄ±cÄ± (YarÄ±n)
```
1. week1_tensors/README.md'yi oku (5 dk)
2. 45 dakikalÄ±k hÄ±zlÄ± sprint'i koÅŸ
   - Data synth
   - Manuel GD
   - nn.Module
   - Test
   - Mini rapor
3. Hedef: Val MSE < 0.5
4. SonuÃ§: week1_summary.md + commit
```

---

## â“ SSS (KÄ±sa)

### Bu bir kurs mu?
```
âŒ Kurs deÄŸil
âœ… Yaparak Ã¶ÄŸrenme protokolÃ¼

Her hafta:
  - Ã–lÃ§Ã¼lebilir hedef
  - GerÃ§ek Ã§Ä±ktÄ±
  - KanÄ±t (artifact)
```

### Sertifika var mÄ±?
```
Portfolyo > Sertifika

Capstone + Repo = KANIT
GitHub profil = CV'de link
"Ä°ÅŸte yaptÄ±ÄŸÄ±m sistem" â†’ Interview'da gÃ¶ster
```

### "Az vaktim var" modu?
```
HaftalÄ±k metrik eÅŸiÄŸini KORU
KapsamÄ± kÃ¼Ã§Ã¼lt:
  - Week 3: Daha kÃ¼Ã§Ã¼k dataset
  - Week 6: Daha kÃ¼Ã§Ã¼k model (3B)
  - Week 7: Temel endpoint'ler (monitoring skip)

EÅŸik geÃ§ilmeli, sÃ¼re esnek olabilir
```

### TakÄ±ldÄ±m, ne yapmalÄ±yÄ±m?
```
1. theory_closure.md'deki checklist (6 adÄ±m)
2. Sorununu daily_log.md'ye yaz
3. Ablation yap (ne zaman baÅŸladÄ±?)
4. Git history kontrol et (son deÄŸiÅŸiklik ne?)
5. Geri dÃ¶n Ã¶nceki Ã§alÄ±ÅŸan commit'e
```

### Daha hÄ±zlÄ± ilerleyebilir miyim?
```
âœ… Metrik eÅŸiÄŸini geÃ§tiysen â†’ Evet
âœ… Artifact'larÄ± oluÅŸturduysan â†’ Evet
âœ… Raporu yazdÄ±ysan â†’ Evet

â†’ Sonraki haftaya geÃ§
(BazÄ± haftalar 3-4 gÃ¼nde biter)
```

### Week 8'den sonra ne olacak?
```
v2 Roadmap:
  - Daha bÃ¼yÃ¼k modeller (13B/70B)
  - Production deployment (AWS/GCP)
  - A/B testing framework
  - Monitoring dashboard (Grafana)
  - CI/CD pipeline
  - Load testing
```

---

## ğŸ“ SonuÃ§

**NovaDev = "Ã–ÄŸrenirken Gemi Yapan" Program**

```
8 Hafta
80-100 Saat
8 Ã‡alÄ±ÅŸan Sistem
1 Capstone Demo

= Portfolyo + Ã–zgÃ¼ven + ML Zihni
```

**BaÅŸarÄ± FormÃ¼lÃ¼:**
```
Teori (Neden?) + Pratik (NasÄ±l?) + ÃœrÃ¼n (KullanÄ±labilir)
= SÃ¼rdÃ¼rÃ¼lebilir Ã–ÄŸrenme
```

**Ä°lk AdÄ±m:**
```bash
cd /Users/onur/code/novadev-protocol
source .venv/bin/activate

# Week 0'Ä± tamamladÄ±n mÄ±?
cat week0_setup/theory_closure.md

# Hepsi âœ“ ise:
cd week1_tensors
cat README.md

# Hadi baÅŸla! ğŸš€
python data_synth.py
```

---

**NovaDev Protocol BaÅŸlÄ±yor! ğŸ’ª**

*Son GÃ¼ncelleme: 2025-10-06*
*Versiyon: 1.0*
