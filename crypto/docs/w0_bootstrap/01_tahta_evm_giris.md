# ğŸ§‘â€ğŸ« Tahta 01 â€” Blockchain'i Okumak: EVM Veri Modeli Deep-Dive

> **AmaÃ§:** "Kripto" deyince sihir deÄŸil, **zincirin kendisini okuyup** anlamlÄ± bilgi Ã§Ä±karmak. Block â†’ Transaction â†’ Receipt â†’ Log â†’ Event akÄ±ÅŸÄ±nÄ± **temelden Ã¼retim seviyesine** anlamak.
> **Mod:** Read-only (Ã¶zel anahtar yok), testnet-first, **yatÄ±rÄ±m tavsiyesi deÄŸildir**.

---

## ğŸ—ºï¸ Plan (DetaylÄ± Tahta)

1. **Blockchain nedir?** (Defter metaforu + gerÃ§ek mimari)
2. **EVM veri katmanlarÄ±:** Block â†’ Tx â†’ Receipt â†’ Log â†’ Event
3. **Event-driven architecture** (Neden log'lar kritik?)
4. **ERC-20 Transfer anatomisi** (Solidity â†’ Blockchain)
5. **JSON-RPC Ã¼Ã§lÃ¼sÃ¼:** blockNumber, getBlock, getLogs
6. **Ä°dempotent + Reorg + State** (Production essentials)
7. **Mini rapor hedefi:** 24h wallet summary
8. **Pratik Ã¶rnekler** + kod ÅŸablonlarÄ±
9. **SÄ±k hatalar** + troubleshooting
10. **Quiz, Ã¶devler, ve next steps**

---

## 1) Blockchain Nedir? (Defter Metaforundan GerÃ§eÄŸe)

### 1.1 Basit Metafor: Defter

```
Blockchain = Bir defter
â”œâ”€â”€ Her sayfa = Block (blok)
â”œâ”€â”€ Sayfadaki satÄ±rlar = Transactions (iÅŸlemler)
â””â”€â”€ SatÄ±r kenarÄ±ndaki notlar = Logs/Events (olaylar)
```

**Ã–rnek sayfa (Block 5,234,567):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block #5,234,567                            â”‚
â”‚ Timestamp: 2025-10-06 14:33:05 UTC         â”‚
â”‚ Parent: #5,234,566                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tx 1: Alice â†’ Bob (1.5 ETH)                â”‚
â”‚   â””â”€ Event: Transfer(Alice, Bob, 1.5)      â”‚
â”‚                                             â”‚
â”‚ Tx 2: Contract.swap(USDC â†’ DAI)            â”‚
â”‚   â”œâ”€ Event: Transfer(User, Pool, 1000)     â”‚
â”‚   â”œâ”€ Event: Swap(...)                      â”‚
â”‚   â””â”€ Event: Transfer(Pool, User, 950)      â”‚
â”‚                                             â”‚
â”‚ Tx 3: Token.mint(NewUser, 100)             â”‚
â”‚   â””â”€ Event: Transfer(0x0, NewUser, 100)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 GerÃ§ek Mimari: Merkle Tree + State

```
Block Header (32 bytes)
â”œâ”€â”€ parentHash        â† Ã–nceki blok (chain continuity)
â”œâ”€â”€ stateRoot         â† Account state Merkle root
â”œâ”€â”€ transactionsRoot  â† Tx Merkle root
â”œâ”€â”€ receiptsRoot      â† Receipt Merkle root (logs burada!)
â”œâ”€â”€ timestamp         â† Unix epoch (seconds)
â”œâ”€â”€ number            â† Block height
â””â”€â”€ ... (difficulty, nonce, etc.)

Block Body
â”œâ”€â”€ Transactions[]    â† Signed user actions
â””â”€â”€ Uncles[]          â† Stale blocks (PoW artifact)

Receipts (separate, indexed by node)
â””â”€â”€ Logs[]            â† Events emitted during execution
```

**Neden bu Ã¶nemli?**
- **Logs zincirde yoktur!** (sadece receipt'lerde)
- Node'lar log'larÄ± **indexler** (getLogs iÃ§in)
- Reorg olunca **receipt'ler kaybolabilir** (son N blok)

---

## 2) EVM Veri KatmanlarÄ±: Block â†’ Tx â†’ Receipt â†’ Log â†’ Event

### 2.1 AkÄ±ÅŸ ÅemasÄ± (Complete Flow)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Action                              â”‚
â”‚          (wallet.transfer, contract.swap, etc.)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRANSACTION (Tx)                         â”‚
â”‚  â€¢ from, to, value, data, nonce, gasPrice, signature       â”‚
â”‚  â€¢ Status: Pending â†’ Mined                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
           ğŸ”¥ EVM Execution (State Change) ğŸ”¥
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RECEIPT                                  â”‚
â”‚  â€¢ status (1=success, 0=revert)                            â”‚
â”‚  â€¢ gasUsed                                                  â”‚
â”‚  â€¢ contractAddress (if deployment)                         â”‚
â”‚  â€¢ logs[] â† â­ Event'ler burada!                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LOGS (Raw)                               â”‚
â”‚  â€¢ address (contract)                                       â”‚
â”‚  â€¢ topics[0..3] (indexed params)                           â”‚
â”‚  â€¢ data (non-indexed params)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EVENTS (Decoded)                         â”‚
â”‚  Transfer(from, to, value)                                  â”‚
â”‚  Swap(sender, amount0In, amount1Out, ...)                  â”‚
â”‚  Approval(owner, spender, value)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Her KatmanÄ±n AmacÄ±

| Katman | AmaÃ§ | Ä°Ã§erik | Sorgulama |
|--------|------|--------|-----------|
| **Block** | Zaman + baÄŸlam | Timestamp, parent, tx root | `eth_getBlockByNumber` |
| **Transaction** | KullanÄ±cÄ± aksiyonu | from, to, value, data | `eth_getTransactionByHash` |
| **Receipt** | SonuÃ§ + yan etkiler | status, gasUsed, **logs** | `eth_getTransactionReceipt` |
| **Log** | Kontrat olayÄ± (ham) | address, topics, data | `eth_getLogs` â­ |
| **Event** | Log'un anlamlÄ± hali | Decoded params | ABI + parsing |

### 2.3 Neden Log/Event Kritik?

**Problem:** "Bu cÃ¼zdana son 24 saatte ne girdi/Ã§Ä±ktÄ±?"

**Ã‡Ã¶zÃ¼m yollarÄ±:**

âŒ **KÃ¶tÃ¼:** Her bloktaki her transaction'Ä± oku â†’ parse et
```python
for block in range(start, end):
    txs = get_block(block)["transactions"]
    for tx in txs:
        if tx["to"] == my_wallet:
            # Parse value...
```
**Neden kÃ¶tÃ¼?** 
- 1000 blok Ã— 200 tx/blok = 200,000 HTTP call!
- Value transfer â‰  token transfer
- Internal transfers (contract â†’ user) gÃ¶rÃ¼nmez

âœ… **Ä°yi:** Event log'larÄ±nÄ± filtrele
```python
logs = eth_getLogs({
    "fromBlock": start,
    "toBlock": end,
    "topics": [TRANSFER_SIG, None, my_wallet_topic]  # to=my_wallet
})
# 1 HTTP call, node indexer kullanÄ±r, hÄ±zlÄ±!
```

**Event-driven architecture:**
- Blockchain = **event stream** (immutable log)
- Off-chain analytics = event'leri consume et
- Real-time alerts = event'leri listen et

---

## 3) Event-Driven Architecture (Neden Bu YaklaÅŸÄ±m?)

### 3.1 Traditional vs Blockchain

**Traditional Database:**
```sql
-- State query
SELECT balance FROM accounts WHERE user_id = 123;

-- History query
SELECT * FROM transactions WHERE user_id = 123;
```

**Blockchain (Event Sourcing):**
```python
# State: Derived from events
events = get_transfer_events(wallet)
balance = sum(e.value for e in events if e.to == wallet) - \
          sum(e.value for e in events if e.from == wallet)

# History: Events themselves
history = events  # Immutable, append-only
```

### 3.2 Event Sourcing Benefits

âœ… **Immutability:** Event'ler asla deÄŸiÅŸmez (audit trail)  
âœ… **Replayability:** Event'leri tekrar oynatarak state'i rebuild et  
âœ… **Transparency:** Her deÄŸiÅŸiklik izlenebilir  
âœ… **Efficiency:** Node'lar event'leri indexler (fast query)

### 3.3 Blockchain'in Ã–zel Durumu

**Challenge:** Blockchain event'ler **asenkron** ve **eventually consistent**

```
Block N-2     Block N-1     Block N   â† Chain tip
  âœ… Finalized   âœ… Likely      âš ï¸ Pending (reorg risk)
                              
â† Safe to index â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€ Buffer â”€â”¤
```

**Ã‡Ã¶zÃ¼m:** **Reorg buffer** (CONFIRMATIONS)

---

## 4) ERC-20 Transfer Anatomisi: Solidity â†’ Blockchain

### 4.1 Solidity Event TanÄ±mÄ±

```solidity
// ERC-20 Interface (EIP-20)
interface IERC20 {
    event Transfer(
        address indexed from,    // indexed â†’ topic
        address indexed to,      // indexed â†’ topic
        uint256 value            // non-indexed â†’ data
    );
    
    function transfer(address to, uint256 amount) external returns (bool);
}

// Implementation example
contract MyToken is IERC20 {
    mapping(address => uint256) public balances;
    
    function transfer(address to, uint256 amount) external returns (bool) {
        require(balances[msg.sender] >= amount, "Insufficient balance");
        
        balances[msg.sender] -= amount;  // State change
        balances[to] += amount;          // State change
        
        emit Transfer(msg.sender, to, amount);  // â­ Event emission
        
        return true;
    }
}
```

### 4.2 Blockchain'e NasÄ±l YazÄ±lÄ±r?

**Event signature hesaplama:**
```python
import hashlib

def keccak256(text):
    """Ethereum'un keccak256'sÄ± (SHA-3 varyantÄ±)"""
    from Crypto.Hash import keccak
    k = keccak.new(digest_bits=256)
    k.update(text.encode())
    return "0x" + k.hexdigest()

# Transfer signature
sig = keccak256("Transfer(address,address,uint256)")
print(sig)
# 0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef
```

**Log yapÄ±sÄ±na mapping:**
```
Solidity Event:
  Transfer(
    address indexed from,     â”€â”€â†’  topics[1]
    address indexed to,       â”€â”€â†’  topics[2]
    uint256 value             â”€â”€â†’  data
  )

Blockchain Log:
{
  "address": "0xTokenContract...",
  "topics": [
    "0xddf252ad...",           # topic[0] = signature (sabit)
    "0x000...from_address",    # topic[1] = from (32 byte padded)
    "0x000...to_address"       # topic[2] = to (32 byte padded)
  ],
  "data": "0x...value_hex"     # 32 byte uint256
}
```

### 4.3 Neden "indexed"? (Topics vs Data)

**Topics (indexed):**
```solidity
event Transfer(
    address indexed from,  // â† Filtrelenebilir!
    address indexed to     // â† Filtrelenebilir!
)
```

**getLogs filtresi:**
```python
# "Bu adresten Ã§Ä±kan tÃ¼m transferler"
logs = eth_getLogs({
    "topics": [
        TRANSFER_SIG,
        from_address_as_topic,  # â† Bu filtre Ã§alÄ±ÅŸÄ±r!
        None  # to: any
    ]
})
```

**Data (non-indexed):**
```solidity
event Transfer(
    uint256 value  // â† Filtreleyemezsin!
)
```

**Trade-off:**
- Indexed: Filtrelenebilir ama max 3 param (+ signature = 4 topic)
- Non-indexed: SÄ±nÄ±rsÄ±z ama filtreleyemezsin, tÃ¼m log'u Ã§ekip parse et

### 4.4 GÃ¶rsel: ABI â†’ Blockchain DÃ¶nÃ¼ÅŸÃ¼mÃ¼

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    SOLIDITY (ABI)                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ event Transfer(                                              â•‘
â•‘   address indexed from,     // 0xAlice = 20 bytes           â•‘
â•‘   address indexed to,       // 0xBob = 20 bytes             â•‘
â•‘   uint256 value             // 1500000000000000000 (1.5e18) â•‘
â•‘ )                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â†“
                    ğŸ”¥ EVM Execution ğŸ”¥
                              â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    BLOCKCHAIN (Log)                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ address: 0x6B175474E89094C44Da98b954EedeAC495271d0F (DAI)    â•‘
â•‘ topics[0]: 0xddf252ad1be2c89b69c2b068fc378daa952ba...       â•‘
â•‘            â†‘ keccak256("Transfer(address,address,uint256)") â•‘
â•‘                                                              â•‘
â•‘ topics[1]: 0x000000000000000000000000Alice1234567890...     â•‘
â•‘            â†‘ from = 0xAlice (padded to 32 bytes)            â•‘
â•‘                                                              â•‘
â•‘ topics[2]: 0x000000000000000000000000Bob1234567890...       â•‘
â•‘            â†‘ to = 0xBob (padded to 32 bytes)                â•‘
â•‘                                                              â•‘
â•‘ data: 0x00000000000000000000000000000000000000000000        â•‘
â•‘       00014D1120D7B16000                                    â•‘
â•‘       â†‘ value = 1500000000000000000 (hex)                   â•‘
â•‘       = 1.5 * 10^18 (with 18 decimals = 1.5 tokens)         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 5) JSON-RPC ÃœÃ§lÃ¼sÃ¼: Hayatta Kalma Kiti

### 5.1 Ã‡ekirdek 3 Komut

| Komut | AmaÃ§ | KullanÄ±m | SÄ±klÄ±k |
|-------|------|----------|--------|
| `eth_blockNumber` | SaÄŸlÄ±k + latency | Health check | Her 10s |
| `eth_getBlockByNumber` | Timestamp + metadata | Zaman Ã§Ã¶zÃ¼mleme | Ä°htiyaÃ§ halinde |
| `eth_getLogs` | Event tarama | Veri Ã§ekme | SÃ¼rekli (loop) |

### 5.2 eth_blockNumber (NabÄ±z Yoklama)

**Ne saÄŸlar?**
- Node canlÄ± mÄ±?
- En son blok numarasÄ±?
- Network latency?

**Ã–rnek implementation:**
```python
import time, requests

def check_health(rpc_url, timeout=10):
    """RPC health check with metrics"""
    payload = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "eth_blockNumber",
        "params": []
    }
    
    t0 = time.perf_counter()
    try:
        r = requests.post(rpc_url, json=payload, timeout=timeout)
        latency_ms = (time.perf_counter() - t0) * 1000
        
        if r.status_code != 200:
            return {"ok": False, "error": f"HTTP {r.status_code}"}
        
        data = r.json()
        if "error" in data:
            return {"ok": False, "error": data["error"]}
        
        block_num = int(data["result"], 16)
        
        # Latency assessment
        status = "ğŸŸ¢" if latency_ms < 300 else \
                 "ğŸŸ¡" if latency_ms < 1000 else "ğŸ”´"
        
        return {
            "ok": True,
            "block": block_num,
            "latency_ms": round(latency_ms, 1),
            "status": status
        }
    
    except requests.exceptions.Timeout:
        return {"ok": False, "error": "Timeout"}
    except Exception as e:
        return {"ok": False, "error": str(e)}

# Usage
result = check_health("https://eth-sepolia.g.alchemy.com/v2/YOUR_KEY")
if result["ok"]:
    print(f"{result['status']} Block: {result['block']:,} | "
          f"Latency: {result['latency_ms']}ms")
else:
    print(f"âŒ Health check failed: {result['error']}")
```

### 5.3 eth_getBlockByNumber (Zaman Makinesi)

**Ne saÄŸlar?**
- Blok timestamp (Unix epoch)
- Parent hash (chain doÄŸrulama)
- Transaction count

**Timestamp kullanÄ±mÄ±:**
```python
def get_block_timestamp(rpc_url, block_number):
    """Get human-readable timestamp"""
    payload = {
        "jsonrpc": "2.0",
        "id": 2,
        "method": "eth_getBlockByNumber",
        "params": [hex(block_number), False]  # False = tx hash only
    }
    
    r = requests.post(rpc_url, json=payload, timeout=10)
    block = r.json()["result"]
    
    ts_hex = block["timestamp"]
    ts_int = int(ts_hex, 16)  # Unix epoch (seconds)
    
    # Human-readable
    import time
    utc_time = time.strftime("%Y-%m-%d %H:%M:%S UTC", 
                             time.gmtime(ts_int))
    
    return {
        "block": block_number,
        "timestamp": ts_int,
        "time_utc": utc_time,
        "tx_count": len(block["transactions"])
    }

# Usage
info = get_block_timestamp(rpc_url, 5_234_567)
print(f"Block {info['block']:,}")
print(f"  Time: {info['time_utc']}")
print(f"  Txs: {info['tx_count']}")
```

**Blok zamandan tahmin etme:**
```python
def estimate_block_at_time(rpc_url, target_timestamp, 
                           avg_block_time=12):
    """
    Belirli bir zamana denk gelen blok numarasÄ±nÄ± tahmin et
    
    Args:
        target_timestamp: Unix timestamp
        avg_block_time: Ortalama blok sÃ¼resi (saniye)
                        Mainnet: ~12s, Sepolia: ~12s
    """
    # Latest block
    latest_num = int(
        requests.post(rpc_url, json={
            "jsonrpc": "2.0",
            "id": 1,
            "method": "eth_blockNumber",
            "params": []
        }).json()["result"], 16
    )
    
    # Latest timestamp
    latest_block = requests.post(rpc_url, json={
        "jsonrpc": "2.0",
        "id": 2,
        "method": "eth_getBlockByNumber",
        "params": [hex(latest_num), False]
    }).json()["result"]
    
    latest_ts = int(latest_block["timestamp"], 16)
    
    # Calculate difference
    time_diff = latest_ts - target_timestamp
    block_diff = time_diff // avg_block_time
    
    estimated_block = latest_num - block_diff
    
    return max(0, estimated_block)

# Example: Blok 24 saat Ã¶nce
target = int(time.time()) - (24 * 3600)
block_24h_ago = estimate_block_at_time(rpc_url, target)
print(f"~24h ago: Block #{block_24h_ago:,}")
```

### 5.4 eth_getLogs (Ã‡ekirdek Ä°ÅŸ)

**En kritik komut!** Event tarama iÃ§in biricik yÃ¶ntem.

**Temel kullanÄ±m:**
```python
def fetch_transfer_logs(rpc_url, start_block, end_block, 
                        token_address=None):
    """
    Transfer event'lerini Ã§ek
    
    Args:
        token_address: Spesifik token (None = tÃ¼m tokenlar)
    """
    TRANSFER_SIG = "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"
    
    filter_obj = {
        "fromBlock": hex(start_block),
        "toBlock": hex(end_block),
        "topics": [TRANSFER_SIG]
    }
    
    # Opsiyonel: Spesifik token
    if token_address:
        filter_obj["address"] = token_address.lower()
    
    payload = {
        "jsonrpc": "2.0",
        "id": 3,
        "method": "eth_getLogs",
        "params": [filter_obj]
    }
    
    r = requests.post(rpc_url, json=payload, timeout=30)
    return r.json()["result"]

# Usage
logs = fetch_transfer_logs(
    rpc_url, 
    start_block=5_230_000, 
    end_block=5_231_000,
    token_address="0x6B175474E89094C44Da98b954EedeAC495271d0F"  # DAI
)
print(f"Found {len(logs)} Transfer events")
```

**Pencere boyutu optimizasyonu:**
```python
def scan_logs_chunked(rpc_url, start, end, chunk_size=1500):
    """
    BÃ¼yÃ¼k aralÄ±ÄŸÄ± kÃ¼Ã§Ã¼k parÃ§alara bÃ¶l
    
    chunk_size: Pencere boyutu (1000-2000 ideal)
    """
    all_logs = []
    
    for a in range(start, end + 1, chunk_size):
        b = min(a + chunk_size - 1, end)
        
        print(f"Scanning {a:,} â†’ {b:,}...")
        
        logs = fetch_transfer_logs(rpc_url, a, b)
        all_logs.extend(logs)
        
        print(f"  Found: {len(logs)} logs")
        
        # Rate limit protection
        time.sleep(0.1)
    
    return all_logs

# Usage
logs = scan_logs_chunked(rpc_url, 5_230_000, 5_240_000)
print(f"Total: {len(logs)} logs")
```

---

## 6) Ä°dempotent + Reorg + State (Production Essentials)

### 6.1 Idempotency (Tekrarlanabilirlik)

**Problem:** Script crash olursa veya tekrar Ã§alÄ±ÅŸtÄ±rÄ±rsan **Ã§ift kayÄ±t** olur

```python
# âŒ Naive approach
for log in logs:
    db.insert({
        "tx": log["transactionHash"],
        "from": parse_from(log),
        "to": parse_to(log),
        "value": parse_value(log)
    })
# Tekrar Ã§alÄ±ÅŸtÄ±r â†’ duplicate entries!
```

**Ã‡Ã¶zÃ¼m 1: UNIQUE constraint**
```sql
CREATE TABLE transfers (
    tx_hash TEXT,
    log_index INTEGER,
    ...
    UNIQUE(tx_hash, log_index)  -- â­ Idempotency key
);
```

**Ã‡Ã¶zÃ¼m 2: Anti-join pattern**
```python
# Staging table kullan
conn.execute("CREATE TEMP TABLE staging AS SELECT * FROM transfers WHERE 1=0")

# Stage'e yaz
for log in logs:
    conn.execute("INSERT INTO staging VALUES (...)")

# Anti-join ile sadece yeni kayÄ±tlarÄ± ekle
conn.execute("""
    INSERT INTO transfers
    SELECT s.*
    FROM staging s
    LEFT JOIN transfers t 
        ON t.tx_hash = s.tx_hash AND t.log_index = s.log_index
    WHERE t.tx_hash IS NULL
""")
```

### 6.2 Reorg Protection (Chain Reorganization)

**Problem:** Son N blok "pending", reorg olabilir

```
Before Reorg:
Block N-2 â†’ Block N-1 â†’ Block N
  âœ…         âœ…          âš ï¸

After Reorg:
Block N-2 â†’ Block N-1' â†’ Block N'
  âœ…         ğŸ”„ New!      ğŸ”„ New!
```

**Ã‡Ã¶zÃ¼m: Confirmation buffer**
```python
CONFIRMATIONS = 12  # Mainnet
# CONFIRMATIONS = 5   # Testnet (faster, riskier)

def get_safe_latest(rpc_url):
    """
    Safe block to process (confirmed)
    """
    latest = int(requests.post(rpc_url, json={
        "jsonrpc": "2.0",
        "id": 1,
        "method": "eth_blockNumber",
        "params": []
    }).json()["result"], 16)
    
    safe_latest = latest - CONFIRMATIONS
    
    return {
        "latest": latest,
        "safe": safe_latest,
        "buffer": CONFIRMATIONS
    }

# Usage
blocks = get_safe_latest(rpc_url)
print(f"Latest: {blocks['latest']:,}")
print(f"Safe:   {blocks['safe']:,} (confirmed)")
print(f"Buffer: {blocks['buffer']} blocks")
```

**Reorg detection:**
```python
def detect_reorg(db, current_block_hash, block_number):
    """
    Reorg tespit et: stored hash â‰  current hash
    """
    stored = db.execute(
        "SELECT block_hash FROM blocks WHERE number = ?", 
        (block_number,)
    ).fetchone()
    
    if stored and stored[0] != current_block_hash:
        print(f"âš ï¸  REORG detected at block {block_number:,}")
        print(f"   Stored:  {stored[0][:10]}...")
        print(f"   Current: {current_block_hash[:10]}...")
        return True
    
    return False
```

### 6.3 State Tracking (Resume Capability)

**Problem:** Script durunca, kaldÄ±ÄŸÄ±n yerden devam et

**Ã‡Ã¶zÃ¼m: State table**
```sql
CREATE TABLE scan_state (
    key TEXT PRIMARY KEY,
    last_scanned_block INTEGER,
    updated_at TIMESTAMP
);
```

**Implementation:**
```python
def get_last_scanned_block(db, key="transfers_v1"):
    """KaldÄ±ÄŸÄ±n yeri al"""
    row = db.execute(
        "SELECT last_scanned_block FROM scan_state WHERE key = ?", 
        (key,)
    ).fetchone()
    
    return row[0] if row else None

def set_last_scanned_block(db, block_num, key="transfers_v1"):
    """Ä°lerlemeyi kaydet"""
    db.execute("""
        INSERT OR REPLACE INTO scan_state (key, last_scanned_block, updated_at)
        VALUES (?, ?, CURRENT_TIMESTAMP)
    """, (key, block_num))
    db.commit()

# Usage
last = get_last_scanned_block(db)
start = last + 1 if last else START_BLOCK

# Scan...
for a in range(start, safe_latest, CHUNK_SIZE):
    b = min(a + CHUNK_SIZE - 1, safe_latest)
    logs = fetch_logs(a, b)
    process_logs(logs)
    set_last_scanned_block(db, b)  # â­ Save progress
    
print(f"âœ… Scanned up to block {b:,}")
```

---

## 7) Mini Rapor Hedefi: 24h Wallet Summary

### 7.1 Hedef Output

```json
{
  "wallet": "0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045",
  "window_hours": 24,
  "inbound": 125.5,
  "outbound": 73.2,
  "net_flow": 52.3,
  "tx_count": 18,
  "top_counterparties": [
    {"address": "0xUniswap...", "amount": 45.0},
    {"address": "0xAave...", "amount": 28.3},
    {"address": "0x1inch...", "amount": 12.5}
  ]
}
```

### 7.2 SQL Query (DuckDB)

```sql
-- 24h window
WITH recent AS (
  SELECT *
  FROM transfers
  WHERE block_time >= NOW() - INTERVAL 24 HOUR
    AND (LOWER(from_addr) = LOWER($wallet) 
         OR LOWER(to_addr) = LOWER($wallet))
),

-- Inbound/Outbound aggregation
agg AS (
  SELECT
    SUM(CASE WHEN LOWER(to_addr) = LOWER($wallet) 
             THEN value_unit ELSE 0 END) AS inbound,
    SUM(CASE WHEN LOWER(from_addr) = LOWER($wallet) 
             THEN value_unit ELSE 0 END) AS outbound,
    COUNT(*) AS tx_count
  FROM recent
),

-- Top counterparties
top_cp AS (
  SELECT
    CASE 
      WHEN LOWER(to_addr) = LOWER($wallet) THEN from_addr
      ELSE to_addr
    END AS counterparty,
    SUM(value_unit) AS total_amount
  FROM recent
  GROUP BY 1
  ORDER BY total_amount DESC
  LIMIT 3
)

SELECT * FROM agg;  -- Main stats
SELECT * FROM top_cp;  -- Top 3
```

### 7.3 Python Implementation

```python
import duckdb
from decimal import Decimal

def generate_wallet_report(db_path, wallet, hours=24):
    """
    Generate wallet activity report
    
    Returns dict with inbound/outbound/top counterparties
    """
    conn = duckdb.connect(db_path)
    wallet_lower = wallet.lower()
    
    # Main aggregation
    agg_query = """
    WITH recent AS (
      SELECT *
      FROM transfers
      WHERE block_time >= NOW() - INTERVAL ? HOUR
        AND (LOWER(from_addr) = ? OR LOWER(to_addr) = ?)
    )
    SELECT
      COALESCE(SUM(CASE WHEN LOWER(to_addr) = ? 
                        THEN value_unit ELSE 0 END), 0) AS inbound,
      COALESCE(SUM(CASE WHEN LOWER(from_addr) = ? 
                        THEN value_unit ELSE 0 END), 0) AS outbound,
      COUNT(*) AS tx_count
    FROM recent
    """
    
    agg = conn.execute(agg_query, [hours, wallet_lower, wallet_lower, 
                                    wallet_lower, wallet_lower]).fetchone()
    
    # Top counterparties
    top_query = """
    WITH recent AS (
      SELECT *
      FROM transfers
      WHERE block_time >= NOW() - INTERVAL ? HOUR
        AND (LOWER(from_addr) = ? OR LOWER(to_addr) = ?)
    )
    SELECT
      CASE WHEN LOWER(to_addr) = ? THEN from_addr ELSE to_addr END AS counterparty,
      SUM(value_unit) AS amount
    FROM recent
    GROUP BY 1
    ORDER BY amount DESC
    LIMIT 3
    """
    
    tops = conn.execute(top_query, [hours, wallet_lower, wallet_lower, 
                                     wallet_lower]).fetchall()
    
    # Build report
    inbound, outbound, tx_count = agg
    
    return {
        "wallet": wallet_lower,
        "window_hours": hours,
        "inbound": float(inbound or 0),
        "outbound": float(outbound or 0),
        "net_flow": float((inbound or 0) - (outbound or 0)),
        "tx_count": int(tx_count or 0),
        "top_counterparties": [
            {"address": addr, "amount": float(amt)}
            for addr, amt in tops
        ]
    }

# Usage
report = generate_wallet_report(
    "onchain.duckdb",
    "0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045",
    hours=24
)

import json
print(json.dumps(report, indent=2))
```

---

## 8) Pratik Ã–rnekler + Kod ÅablonlarÄ±

### 8.1 Complete Ingest Pipeline

```python
#!/usr/bin/env python3
"""
Production-grade Transfer ingest pipeline
"""
import os, time, requests, duckdb
from pathlib import Path
from dotenv import load_dotenv

# Config
load_dotenv()
RPC_URL = os.getenv("RPC_URL")
DB_PATH = Path("onchain.duckdb")
TRANSFER_SIG = "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"
CONFIRMATIONS = 12
CHUNK_SIZE = 1500
STATE_KEY = "transfers_v1"

def init_db():
    """Initialize database schema"""
    conn = duckdb.connect(str(DB_PATH))
    
    # Transfers table
    conn.execute("""
    CREATE TABLE IF NOT EXISTS transfers (
        block_number BIGINT,
        block_time TIMESTAMP,
        tx_hash TEXT,
        log_index INTEGER,
        token TEXT,
        from_addr TEXT,
        to_addr TEXT,
        raw_value DECIMAL(38,0),
        value_unit DOUBLE,
        UNIQUE(tx_hash, log_index)  -- Idempotency
    )
    """)
    
    # State tracking
    conn.execute("""
    CREATE TABLE IF NOT EXISTS scan_state (
        key TEXT PRIMARY KEY,
        last_scanned_block BIGINT,
        updated_at TIMESTAMP
    )
    """)
    
    # Indexes
    conn.execute("CREATE INDEX IF NOT EXISTS idx_block ON transfers(block_number)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_from ON transfers(from_addr)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_to ON transfers(to_addr)")
    
    return conn

def rpc_call(method, params):
    """RPC helper"""
    r = requests.post(RPC_URL, json={
        "jsonrpc": "2.0",
        "id": 1,
        "method": method,
        "params": params
    }, timeout=30)
    
    r.raise_for_status()
    data = r.json()
    
    if "error" in data:
        raise RuntimeError(data["error"])
    
    return data["result"]

def get_safe_latest():
    """Get confirmed block number"""
    latest_hex = rpc_call("eth_blockNumber", [])
    latest = int(latest_hex, 16)
    return latest - CONFIRMATIONS

def get_block_timestamp(block_num):
    """Get block timestamp"""
    block = rpc_call("eth_getBlockByNumber", [hex(block_num), False])
    ts = int(block["timestamp"], 16)
    return time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime(ts))

def fetch_logs(start, end):
    """Fetch Transfer logs"""
    return rpc_call("eth_getLogs", [{
        "fromBlock": hex(start),
        "toBlock": hex(end),
        "topics": [TRANSFER_SIG]
    }])

def parse_log(log, decimals=18):
    """Parse Transfer log"""
    topics = log["topics"]
    
    from_addr = "0x" + topics[1][-40:]
    to_addr = "0x" + topics[2][-40:]
    raw_value = int(log["data"], 16)
    value_unit = raw_value / (10 ** decimals)
    
    return {
        "block_number": int(log["blockNumber"], 16),
        "tx_hash": log["transactionHash"].lower(),
        "log_index": int(log["logIndex"], 16),
        "token": log["address"].lower(),
        "from_addr": from_addr.lower(),
        "to_addr": to_addr.lower(),
        "raw_value": raw_value,
        "value_unit": value_unit
    }

def main():
    """Main ingest loop"""
    conn = init_db()
    
    # Get start block
    last = conn.execute(
        "SELECT last_scanned_block FROM scan_state WHERE key = ?",
        [STATE_KEY]
    ).fetchone()
    
    start = (last[0] + 1) if last else 5_000_000  # Sepolia start
    safe_latest = get_safe_latest()
    
    if start >= safe_latest:
        print(f"âœ… Up to date: {start:,} >= {safe_latest:,}")
        return
    
    print(f"ğŸ” Scanning {start:,} â†’ {safe_latest:,}")
    
    # Chunk scanning
    for a in range(start, safe_latest + 1, CHUNK_SIZE):
        b = min(a + CHUNK_SIZE - 1, safe_latest)
        
        print(f"   [{a:,} - {b:,}]", end=" ")
        
        logs = fetch_logs(a, b)
        
        if logs:
            # Get block timestamp (cache for batch)
            ts_cache = {}
            for log in logs:
                bn = int(log["blockNumber"], 16)
                if bn not in ts_cache:
                    ts_cache[bn] = get_block_timestamp(bn)
            
            # Parse & insert (idempotent)
            rows = []
            for log in logs:
                parsed = parse_log(log)
                bn = parsed["block_number"]
                rows.append((
                    bn,
                    ts_cache[bn],
                    parsed["tx_hash"],
                    parsed["log_index"],
                    parsed["token"],
                    parsed["from_addr"],
                    parsed["to_addr"],
                    parsed["raw_value"],
                    parsed["value_unit"]
                ))
            
            # Anti-join insert
            conn.execute("CREATE TEMP TABLE _staging AS SELECT * FROM transfers WHERE 1=0")
            conn.executemany("INSERT INTO _staging VALUES (?,?,?,?,?,?,?,?,?)", rows)
            conn.execute("""
                INSERT INTO transfers
                SELECT s.*
                FROM _staging s
                LEFT JOIN transfers t ON t.tx_hash = s.tx_hash AND t.log_index = s.log_index
                WHERE t.tx_hash IS NULL
            """)
            conn.execute("DROP TABLE _staging")
            
            print(f"âœ… +{len(rows)} logs")
        else:
            print("âšª 0 logs")
        
        # Update state
        conn.execute("""
            INSERT OR REPLACE INTO scan_state (key, last_scanned_block, updated_at)
            VALUES (?, ?, CURRENT_TIMESTAMP)
        """, [STATE_KEY, b])
        conn.commit()
        
        time.sleep(0.1)  # Rate limit
    
    print(f"âœ… Done. Last scanned: {b:,}")

if __name__ == "__main__":
    main()
```

---

## 9) SÄ±k Hatalar + Troubleshooting

### âŒ Hata 1: Decimals Unutmak
```python
# YANLIÅ
raw = 1000000000000000000
print(f"Value: {raw}")  # 1000000000000000000 (anlamsÄ±z!)

# DOÄRU
raw = 1000000000000000000
decimals = 18
value = raw / (10 ** decimals)
print(f"Value: {value} tokens")  # 1.0 (anlamlÄ±!)
```

### âŒ Hata 2: GeniÅŸ getLogs Penceresi
```python
# YANLIÅ (timeout risk!)
logs = eth_getLogs({
    "fromBlock": "0x0",  # Genesis!
    "toBlock": "latest"  # TÃ¼m chain!
})
# Result: Timeout / 429 / query too large

# DOÄRU (kÃ¼Ã§Ã¼k parÃ§alar)
for start in range(5_000_000, 5_100_000, 1500):
    end = min(start + 1499, 5_100_000)
    logs = eth_getLogs({"fromBlock": hex(start), "toBlock": hex(end)})
```

### âŒ Hata 3: Reorg GÃ¶rmezden Gelmek
```python
# YANLIÅ
latest = get_block_number()
logs = scan_logs(latest - 1000, latest)  # Son bloklar pending!

# DOÄRU
latest = get_block_number()
safe = latest - CONFIRMATIONS
logs = scan_logs(safe - 1000, safe)
```

### âŒ Hata 4: Idempotency Key Eksik
```python
# YANLIÅ (aynÄ± tx'te 2+ transfer olabilir!)
unique_key = log["transactionHash"]

# DOÄRU
unique_key = (log["transactionHash"], log["logIndex"])
```

### âŒ Hata 5: State Tracking Yok
```python
# YANLIÅ (her seferinde baÅŸtan)
scan_logs(START_BLOCK, latest)  # Crash olsa baÅŸtan!

# DOÄRU
last_scanned = get_last_scanned_block(db)
start = last_scanned + 1 if last_scanned else START_BLOCK
scan_logs(start, latest)
set_last_scanned_block(db, latest)  # â­ Save progress
```

---

## 10) Quiz + Ã–devler

### Mini Quiz (8 Soru)

1. Blockchain'de log'lar nerede saklanÄ±r?
2. Event-driven architecture'Ä±n 3 avantajÄ±?
3. `eth_getLogs` neden `eth_getTransactionByHash`'ten daha verimli?
4. Transfer event'inde topic0 ne iÃ§erir?
5. Ä°dempotency key neden `(tx_hash, log_index)` Ã§ifti?
6. Reorg buffer neden gerekli?
7. DuckDB anti-join pattern'i nasÄ±l Ã§alÄ±ÅŸÄ±r?
8. 24h wallet report iÃ§in hangi SQL aggregate'leri kullanÄ±lÄ±r?

### Cevap AnahtarÄ±

1. **Receipt'lerde** (block body'de deÄŸil); node'lar indexler
2. (a) Immutability, (b) Replayability, (c) Transparency
3. getLogs **filtrelenebilir** (topics), node index'i kullanÄ±r; tx-by-hash her tx'i tek tek sorgular
4. Event signature: `keccak256("Transfer(address,address,uint256)")`
5. Bir tx'te birden fazla log olabilir; `log_index` tekliÄŸi garanti eder
6. Son N blok **reorg** (fork) olabilir; confirmed block'lara odaklan
7. Staging table â†’ LEFT JOIN â†’ WHERE main.key IS NULL â†’ INSERT (sadece yeni kayÄ±tlar)
8. `SUM(CASE WHEN ...)`, `COUNT(*)`, `GROUP BY counterparty`, `LIMIT 3`

### Ã–devler (4 Pratik)

#### Ã–dev 1: Health Monitor
```python
# 5 dakika boyunca her 10 saniyede blockNumber Ã§aÄŸÄ±r
# Latency'leri kaydet (CSV)
# Min/max/avg latency hesapla
```

#### Ã–dev 2: Block Time Analysis
```python
# Son 1000 bloÄŸun timestamp'lerini al
# Ortalama blok sÃ¼resini hesapla (saniye)
# Histogram Ã§iz (matplotlib)
```

#### Ã–dev 3: Mini Ingest
```python
# 1000 blok Transfer log'u Ã§ek
# DuckDB'ye yaz (idempotent)
# Tekrar Ã§alÄ±ÅŸtÄ±r â†’ Ã§ift kayÄ±t olmamalÄ±
```

#### Ã–dev 4: Wallet Report
```python
# Bir cÃ¼zdan seÃ§ (Sepolia testnet)
# 24h raporu Ã¼ret (JSON format)
# Top 3 counterparty'yi validate et
```

---

## 11) Terimler SÃ¶zlÃ¼ÄŸÃ¼

| Terim | TanÄ±m |
|-------|-------|
| **Block** | Zincirdeki sÄ±ralÄ± sayfa; timestamp + tx'ler |
| **Transaction** | KullanÄ±cÄ± aksiyonu (signed) |
| **Receipt** | Tx sonucu; status + gasUsed + **logs** |
| **Log** | Kontrat event'i (ham); topics + data |
| **Event** | Log'un decoded hali (ABI ile) |
| **Topic** | Indexed event parametresi (max 3 + signature) |
| **Data** | Non-indexed parametreler |
| **Event Sourcing** | State'i event'lerden tÃ¼ret |
| **Idempotency** | Tekrar Ã§alÄ±ÅŸtÄ±rÄ±labilirlik (aynÄ± sonuÃ§) |
| **Reorg** | Chain reorganization (fork) |
| **Confirmation** | Block kesinleÅŸme seviyesi |
| **State Tracking** | Ä°lerleme kaydetme (resume) |

---

## ğŸ”— Ä°lgili Kaynaklar

### Repo KodlarÄ±
- `crypto/w0_bootstrap/rpc_health.py` â†’ blockNumber + latency
- `crypto/w0_bootstrap/capture_transfers_idempotent.py` â†’ Full ingest pipeline
- `crypto/w0_bootstrap/report_json.py` â†’ Wallet report generator

### Next Lessons
- **â†’ Tahta 02:** [JSON-RPC 101](02_tahta_rpc_101.md) (detaylÄ± RPC komutlarÄ±)
- **â†’ Tahta 03:** [Transfer Anatomisi](03_tahta_transfer_anatomi.md) (topics/data parsing)
- **â†’ Tahta 04:** [getLogs + Reorg](04_tahta_getlogs_pencere_reorg.md) (Coming)

### External
- **Ethereum JSON-RPC:** https://ethereum.org/en/developers/docs/apis/json-rpc/
- **ERC-20 Standard:** https://eips.ethereum.org/EIPS/eip-20
- **DuckDB SQL:** https://duckdb.org/docs/

---

## ğŸ›¡ï¸ GÃ¼venlik / Etik

- **Read-only:** Ã–zel anahtar yok, imza yok, custody yok
- **`.env` hygiene:** Secrets asla commit etme
- **Testnet-first:** Sepolia ile baÅŸla
- **EÄŸitim amaÃ§lÄ±:** YatÄ±rÄ±m tavsiyesi deÄŸildir

---

## ğŸ”— Navigasyon

- **â†’ Sonraki:** [02 - JSON-RPC 101](02_tahta_rpc_101.md)
- **â†‘ Ä°ndeks:** [W0 Tahta Serisi](README.md)

---

**Tahta 01 â€” Blockchain'i Okumak: EVM Veri Modeli**  
*Format: Temelden Production-Ready*  
*SÃ¼re: 60-75 dk (GeliÅŸtirilmiÅŸ Versiyon)*  
*Prerequisite: Yok (sÄ±fÄ±rdan baÅŸlar)*  
*Versiyon: 2.0 (Complete Rewrite)*