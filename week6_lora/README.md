# Hafta 6: Fine-tune (LoRA/QLoRA)

**Hedef:** 7B modeli kÃ¼Ã§Ã¼k domain'e uyarla (PEFT/LoRA), before/after A/B test.

---

## ğŸ“š Konular

- PEFT & LoRA
- Low-rank adaptation
- Training efficiency (dÃ¼ÅŸÃ¼k batch, gradient accumulation)

---

## ğŸ¯ Teslim

- `finetune_lora/`: Training script
- `eval.md`: A/B test raporu

---

**Durum:** ğŸ”œ YakÄ±nda baÅŸlayacak
