# Hafta 6: Fine-tune (LoRA/QLoRA)

**Hedef:** 7B modeli küçük domain'e uyarla (PEFT/LoRA), before/after A/B test.

---

## 📚 Konular

- PEFT & LoRA
- Low-rank adaptation
- Training efficiency (düşük batch, gradient accumulation)

---

## 🎯 Teslim

- `finetune_lora/`: Training script
- `eval.md`: A/B test raporu

---

**Durum:** 🔜 Yakında başlayacak
